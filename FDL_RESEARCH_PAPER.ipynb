{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzBES5ncP0jN",
        "outputId": "d2f2f116-7f80-45d3-ea26-8d89076cb911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub torch torchvision tqdm --quiet\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"fedesoriano/cifar100\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjJKSsxsSAZe",
        "outputId": "441e5095-c64c-401f-9152-498ee78079a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'cifar100' dataset.\n",
            "Path to dataset files: /kaggle/input/cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-100 class names (in torchvision order)\n",
        "CIFAR100_CLASSES = datasets.CIFAR100(root=\".\", download=True).classes\n",
        "\n",
        "superclasses = {\n",
        "    \"aquatic_mammals\": [\"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\"],\n",
        "    \"fish\": [\"aquarium_fish\", \"flatfish\", \"ray\", \"shark\", \"trout\"],\n",
        "    \"flowers\": [\"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\"],\n",
        "    \"food_containers\": [\"bottle\", \"bowl\", \"can\", \"cup\", \"plate\"],\n",
        "    \"fruit_and_vegetables\": [\"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet_pepper\"],\n",
        "}\n",
        "\n",
        "chosen_classes = [cls for group in superclasses.values() for cls in group]\n",
        "chosen_class_indices = [CIFAR100_CLASSES.index(cls) for cls in chosen_classes]\n",
        "\n",
        "print(\"Chosen classes (25 total):\", chosen_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEHkwavsTZKN",
        "outputId": "cd845814-8937-4788-e178-e0f6a6c059ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen classes (25 total): ['beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium_fish', 'flatfish', 'ray', 'shark', 'trout', 'orchid', 'poppy', 'rose', 'sunflower', 'tulip', 'bottle', 'bowl', 'can', 'cup', 'plate', 'apple', 'mushroom', 'orange', 'pear', 'sweet_pepper']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "train_full = datasets.CIFAR100(root=\".\", train=True, download=True, transform=transform)\n",
        "test_full  = datasets.CIFAR100(root=\".\", train=False, download=True, transform=transform)\n",
        "\n",
        "def remap_labels(dataset, allowed_indices):\n",
        "    \"\"\"Filter dataset and relabel classes from 0..N-1\"\"\"\n",
        "    mapping = {orig:new for new, orig in enumerate(allowed_indices)}\n",
        "    imgs, labels = [], []\n",
        "    for img, lbl in dataset:\n",
        "        if lbl in allowed_indices:\n",
        "            imgs.append(img)\n",
        "            labels.append(mapping[lbl])\n",
        "    return TensorDataset(torch.stack(imgs), torch.tensor(labels))\n",
        "\n",
        "# Phase 1 = first 3 classes per superclass (5×3 = 15 classes)\n",
        "phase1_classes = [cls for group in superclasses.values() for cls in group[:3]]\n",
        "phase1_indices = [CIFAR100_CLASSES.index(cls) for cls in phase1_classes]\n",
        "\n",
        "train_phase1 = remap_labels(train_full, phase1_indices)\n",
        "test_phase1  = remap_labels(test_full, phase1_indices)\n",
        "train_phase2 = remap_labels(train_full, chosen_class_indices)\n",
        "test_phase2  = remap_labels(test_full, chosen_class_indices)\n",
        "\n",
        "print(f\"Phase1 → {len(train_phase1)} train / {len(test_phase1)} test\")\n",
        "print(f\"Phase2 → {len(train_phase2)} train / {len(test_phase2)} test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3ivxxNQa1m1",
        "outputId": "9904cd18-a1f3-4378-d1c7-dc66892917db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase1 → 7500 train / 1500 test\n",
            "Phase2 → 12500 train / 2500 test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(64*8*8, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64*8*8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "print(\"✅ CNN ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dyssa9qa4YH",
        "outputId": "dbcaf276-11e2-4f6e-ff98-58abcaaa586d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CNN ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for imgs, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total * 100\n"
      ],
      "metadata": {
        "id": "bnaHSfF1bAkg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_p1 = DataLoader(train_phase1, batch_size=64, shuffle=True)\n",
        "test_loader_p1  = DataLoader(test_phase1, batch_size=64, shuffle=False)\n",
        "\n",
        "model_p1 = SimpleCNN(num_classes=len(phase1_indices)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_p1.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model_p1, train_loader_p1, criterion, optimizer, epochs=5)\n",
        "phase1_acc = evaluate_model(model_p1, test_loader_p1)\n",
        "print(f\"✅ Phase 1 Accuracy: {phase1_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZzTCjyQbDCh",
        "outputId": "ecc94c53-97eb-4c8b-9a69-addddbef5fce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 118/118 [00:01<00:00, 81.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.9735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 118/118 [00:01<00:00, 96.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 1.4894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 118/118 [00:01<00:00, 98.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 1.2556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 118/118 [00:01<00:00, 61.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 1.0592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 118/118 [00:01<00:00, 59.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 0.9215\n",
            "✅ Phase 1 Accuracy: 61.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_p2 = DataLoader(train_phase2, batch_size=64, shuffle=True)\n",
        "test_loader_p2  = DataLoader(test_phase2, batch_size=64, shuffle=False)\n",
        "\n",
        "model_p2 = SimpleCNN(num_classes=len(chosen_class_indices)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_p2.parameters(), lr=0.001)\n",
        "\n",
        "phase2_acc_list = []\n",
        "epochs_needed = None\n",
        "\n",
        "for epoch in range(1, 6):  # up to 15 epochs\n",
        "    train_model(model_p2, train_loader_p2, criterion, optimizer, epochs=1)\n",
        "    acc = evaluate_model(model_p2, test_loader_p2)\n",
        "    phase2_acc_list.append(acc)\n",
        "    print(f\"Epoch {epoch} → Accuracy {acc:.2f}%\")\n",
        "    if acc >= phase1_acc and epochs_needed is None:\n",
        "        epochs_needed = epoch\n",
        "\n",
        "final_phase2_acc = phase2_acc_list[-1]\n",
        "print(f\"\\n✅ Final Phase 2 Accuracy: {final_phase2_acc:.2f}%\")\n",
        "print(f\"📊 Accuracy Difference = {final_phase2_acc - phase1_acc:.2f}%\")\n",
        "if epochs_needed:\n",
        "    print(f\"🕓 Epochs in Phase 2 to reach Phase 1 accuracy: {epochs_needed}\")\n",
        "else:\n",
        "    print(\"⚠️ Phase 2 never matched Phase 1 accuracy within 15 epochs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z--iuuRwbGck",
        "outputId": "0a633dd1-2d88-4faa-b22e-d8509237ef7b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 196/196 [00:01<00:00, 170.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 2.3267\n",
            "Epoch 1 → Accuracy 39.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 196/196 [00:01<00:00, 181.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.7831\n",
            "Epoch 2 → Accuracy 46.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 196/196 [00:01<00:00, 164.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.5163\n",
            "Epoch 3 → Accuracy 49.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 196/196 [00:01<00:00, 176.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.3094\n",
            "Epoch 4 → Accuracy 51.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 196/196 [00:01<00:00, 186.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 1.1091\n",
            "Epoch 5 → Accuracy 50.76%\n",
            "\n",
            "✅ Final Phase 2 Accuracy: 50.76%\n",
            "📊 Accuracy Difference = -10.77%\n",
            "⚠️ Phase 2 never matched Phase 1 accuracy within 15 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== SUMMARY =====\")\n",
        "print(f\"Phase 1 Accuracy: {phase1_acc:.2f}%\")\n",
        "print(f\"Final Phase 2 Accuracy: {final_phase2_acc:.2f}%\")\n",
        "print(f\"Accuracy Difference: {final_phase2_acc - phase1_acc:.2f}%\")\n",
        "if epochs_needed:\n",
        "    print(f\"Epochs to reach Phase 1 Accuracy in Phase 2: {epochs_needed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EaDjea8bKh1",
        "outputId": "ecb0a8ef-8a3a-4c05-864e-e006cede75a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== SUMMARY =====\n",
            "Phase 1 Accuracy: 61.53%\n",
            "Final Phase 2 Accuracy: 51.48%\n",
            "Accuracy Difference: -10.05%\n"
          ]
        }
      ]
    }
  ]
}